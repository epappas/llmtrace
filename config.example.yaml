# ============================================================================
# LLMTrace Proxy — Example Configuration
# ============================================================================
#
# Copy this file to config.yaml and adjust values for your environment.
#
# Usage:
#   llmtrace-proxy --config config.yaml          # start the proxy
#   llmtrace-proxy validate --config config.yaml  # validate without starting
#   llmtrace-proxy --help                          # show CLI help
#   llmtrace-proxy --version                       # show version
#
# Environment variable overrides (highest precedence after CLI flags):
#   LLMTRACE_CONFIG                — path to this config file
#   LLMTRACE_LISTEN_ADDR           — override listen_addr
#   LLMTRACE_UPSTREAM_URL          — override upstream_url
#   LLMTRACE_STORAGE_PROFILE       — override storage.profile
#   LLMTRACE_STORAGE_DATABASE_PATH — override storage.database_path
#   LLMTRACE_CLICKHOUSE_URL        — override storage.clickhouse_url
#   LLMTRACE_CLICKHOUSE_DATABASE   — override storage.clickhouse_database
#   LLMTRACE_POSTGRES_URL          — override storage.postgres_url
#   LLMTRACE_REDIS_URL             — override storage.redis_url
#   LLMTRACE_LOG_LEVEL             — override logging.level
#   LLMTRACE_LOG_FORMAT            — override logging.format
#   RUST_LOG                       — fine-grained tracing filter (e.g. "llmtrace_proxy=debug,info")
# ============================================================================

# ---------------------------------------------------------------------------
# Network
# ---------------------------------------------------------------------------

# Address and port to bind the proxy server to.
listen_addr: "0.0.0.0:8080"

# Upstream LLM provider URL (OpenAI, vLLM, Ollama, etc.).
upstream_url: "https://api.openai.com"

# ---------------------------------------------------------------------------
# Storage
# ---------------------------------------------------------------------------

storage:
  # Profile: "lite" (SQLite, zero infrastructure), "memory" (in-memory, lost on restart),
  # or "production" (ClickHouse + PostgreSQL + Redis — see docker-compose.yml).
  profile: "lite"
  # Database file path (used by the "lite" profile).
  database_path: "llmtrace.db"

  # --- Production profile settings (only used when profile = "production") ---
  # ClickHouse HTTP URL for trace/span analytical storage.
  # clickhouse_url: "http://localhost:8123"
  # ClickHouse database name (created automatically on startup).
  # clickhouse_database: "llmtrace"
  # PostgreSQL connection URL for metadata (tenants, configs, audit events).
  # postgres_url: "postgres://llmtrace:llmtrace@localhost:5432/llmtrace"
  # Redis connection URL for hot-query cache and sessions.
  # redis_url: "redis://127.0.0.1:6379"

# ---------------------------------------------------------------------------
# Logging
# ---------------------------------------------------------------------------

logging:
  # Log level: trace, debug, info, warn, error.
  # Can be overridden by LLMTRACE_LOG_LEVEL env var or --log-level CLI flag.
  # RUST_LOG env var takes highest precedence for fine-grained control.
  level: "info"
  # Output format: "text" (human-readable) or "json" (structured, machine-parseable).
  # Can be overridden by LLMTRACE_LOG_FORMAT env var or --log-format CLI flag.
  format: "text"

# ---------------------------------------------------------------------------
# Timeouts
# ---------------------------------------------------------------------------

# Request timeout in milliseconds (covers full upstream round-trip).
timeout_ms: 30000

# Connection timeout in milliseconds (TCP connect phase only).
connection_timeout_ms: 5000

# Maximum number of concurrent connections.
max_connections: 1000

# ---------------------------------------------------------------------------
# TLS (for the proxy listener itself)
# ---------------------------------------------------------------------------

enable_tls: false
# tls_cert_file: "/etc/ssl/certs/proxy.crt"
# tls_key_file: "/etc/ssl/private/proxy.key"

# ---------------------------------------------------------------------------
# Feature toggles
# ---------------------------------------------------------------------------

# Enable regex-based security analysis (prompt injection, PII detection).
enable_security_analysis: true

# Enable trace storage to the configured storage backend.
enable_trace_storage: true

# Enable streaming SSE passthrough for "stream": true requests.
enable_streaming: true

# Maximum request body size in bytes (default: 50 MB).
max_request_size_bytes: 52428800

# Timeout for async security analysis in milliseconds.
security_analysis_timeout_ms: 5000

# Timeout for async trace storage in milliseconds.
trace_storage_timeout_ms: 10000

# ---------------------------------------------------------------------------
# Rate limiting
# ---------------------------------------------------------------------------

rate_limiting:
  enabled: true
  requests_per_second: 100
  burst_size: 200
  window_seconds: 60

# ---------------------------------------------------------------------------
# Circuit breaker — degrades to pure pass-through on repeated failures
# ---------------------------------------------------------------------------

circuit_breaker:
  enabled: true
  # Number of consecutive failures before opening the circuit.
  failure_threshold: 10
  # Time in ms to wait before trying a probe call (half-open state).
  recovery_timeout_ms: 30000
  # Number of probe calls allowed in half-open state.
  half_open_max_calls: 3

# ---------------------------------------------------------------------------
# Alert engine — webhook notifications for security findings
# ---------------------------------------------------------------------------

alerts:
  # Enable the alert engine. When enabled, security findings that exceed the
  # configured thresholds will trigger an HTTP POST to the webhook URL.
  enabled: false
  # Webhook URL to POST alert payloads to (Slack incoming webhooks, generic, etc.).
  # Slack-format payloads are sent automatically when the URL contains hooks.slack.com.
  webhook_url: ""
  # Minimum severity level to trigger an alert: Info, Low, Medium, High, Critical.
  min_severity: "High"
  # Minimum confidence-based score (0-100) to trigger an alert.
  min_security_score: 70
  # Cooldown in seconds between repeated alerts for the same finding type.
  cooldown_seconds: 300

# ---------------------------------------------------------------------------
# Cost caps — per-agent budget & token enforcement
# ---------------------------------------------------------------------------

cost_caps:
  # Enable cost cap enforcement. When enabled, requests are checked against
  # budget limits (USD) and per-request token caps before being forwarded.
  enabled: false

  # Default budget caps applied to all tenants/agents unless overridden.
  # Each cap specifies a time window and a hard limit. Requests that would
  # push spend above the hard limit are rejected with HTTP 429.
  # Soft limits trigger an alert but still allow the request through.
  default_budget_caps:
    - window: hourly
      hard_limit_usd: 10.0
      soft_limit_usd: 8.0
    - window: daily
      hard_limit_usd: 100.0
      # soft_limit_usd: 80.0

  # Default per-request token caps (applied before the request is forwarded).
  # default_token_cap:
  #   max_prompt_tokens: 8192
  #   max_completion_tokens: 4096
  #   max_total_tokens: 16384

  # Per-agent overrides. An agent is identified by the X-LLMTrace-Agent-ID header.
  # agents:
  #   - agent_id: "heavy-agent"
  #     budget_caps:
  #       - window: daily
  #         hard_limit_usd: 500.0
  #         soft_limit_usd: 400.0
  #     token_cap:
  #       max_prompt_tokens: 16384
  #       max_completion_tokens: 8192

# ---------------------------------------------------------------------------
# gRPC ingestion gateway — high-throughput trace ingestion via tonic
# ---------------------------------------------------------------------------

grpc:
  # Enable the gRPC ingestion endpoint. When enabled, the proxy starts a
  # tonic gRPC server on a separate listen address that accepts traces in
  # the LLMTrace-native protobuf format (see proto/llmtrace.proto).
  # Supports both unary batch and client-side streaming RPCs.
  enabled: false
  # Address and port to bind the gRPC server to.
  listen_addr: "0.0.0.0:50051"

# ---------------------------------------------------------------------------
# Streaming security analysis — real-time analysis during SSE streaming
# ---------------------------------------------------------------------------

streaming_analysis:
  # Enable incremental regex-based security checks during SSE streaming.
  # When enabled, the proxy runs lightweight pattern matching every N tokens
  # while the stream is still in progress. Findings are tagged with
  # "detection": "streaming" metadata and critical issues trigger alerts
  # mid-stream rather than waiting for stream completion.
  enabled: false
  # Number of completion tokens between each incremental analysis check.
  # Lower values detect threats faster but add marginal CPU overhead per chunk.
  token_interval: 50

# ---------------------------------------------------------------------------
# Health check endpoint
# ---------------------------------------------------------------------------

health_check:
  enabled: true
  path: "/health"
  interval_seconds: 10
  timeout_ms: 5000
  retries: 3
